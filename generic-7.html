<!DOCTYPE HTML>
<!--
	Stellar by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Generic - Stellar by HTML5 UP</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
					<header id="header">
						<h1>Stress-Testing LLMs on Legal Compression</h1>
						<p>Blog</p>
					</header>

				<!-- Main -->
					<div id="main">

						<!-- Content -->
							<section id="content" class="main">
								<h2>Introduction</h2>
								<p> Indian Court judgments are famously long, intricate, and packed with layered reasoning. For anyone working with public policy, law, or research, turning these massive texts into clear, reliable summaries is almost a project by itself. Thus I'm here trying to test whether modern language models can summarise Indian legal judgments with accuracy, structure, and speed.

To explore this, I put three very different models to work — Google Gemini, Phi-4 Mini (running locally through Ollama), and Facebook BART. Each comes with its own strengths, quirks, and limits, making them ideal for a comparative test. My goal wasn’t to chase perfection, but to understand how well these models handle long-form judicial reasoning, how they behave under load, and where they start to struggle.

This blog documents that journey — from extracting text to chunking, prompting, debugging, and watching the models do their best (and sometimes fail spectacularly) to summarise some of India’s most complex constitutional judgments. It’s a practical look at what really happens when AI meets legal analysis, and what we can learn from the process. </p>		 	                            

								<h3> Why Legal Judgments Are the Final Boss of NLP</h3>
								<p> 

The nature of Indian Supreme Court judgments: long, dense, layered with facts, arguments, citations, and constitutional doctrine.

That is why summarising them is difficult: nuance, accuracy, logical continuity, and massive length.

The framework proposed in Evaluating Large Language Models by Irina Sigler and Yuan Xu offers a grounded way to think about how we measure an LLM’s real-world performance.
			
                                </ul>
								<ul class="actions special">
									<li><a href="https://www.kaggle.com/code/arushirawat/brent-oil-price-forecasting" class="button">Click to view the project</a></li>
								</ul>
							</section>

					</div>
